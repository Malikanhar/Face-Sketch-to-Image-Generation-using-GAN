{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import natsort\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filename(path):\n",
    "    dirFiles = os.listdir(path)\n",
    "    for i, file in enumerate(dirFiles):\n",
    "        dirFiles[i] = path + file\n",
    "    return natsort.natsorted(dirFiles ,reverse=False)\n",
    "\n",
    "# load all images in a directory into memory\n",
    "def load_images(list_path, size=(256, 256)):\n",
    "    img_list = list()\n",
    "    # enumerate filenames in directory, assume all are images\n",
    "    for filename in list_path:\n",
    "        # load and resize the image\n",
    "        pixels = load_img(filename, target_size=size)\n",
    "        # convert to numpy array\n",
    "        pixels = img_to_array(pixels)\n",
    "        pixels = (pixels - 127.5) / 127.5\n",
    "        img_list.append(pixels)\n",
    "    return np.asarray(img_list)\n",
    "\n",
    "def pred_images(g_model, target_dir, filenames, batch_size=128):\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "\n",
    "    imgs = load_images(filenames)\n",
    "    g_img = g_model.predict(imgs)\n",
    "    g_img = g_img * 127.5 + 127.5\n",
    "    for j, _img in enumerate(g_img):\n",
    "        cv2.imwrite(target_dir + \"/\" + os.path.basename(filenames[j]), cv2.resize(cv2.cvtColor(_img.astype('uint8'), cv2.COLOR_RGB2BGR), (200, 250)))\n",
    "    print(\"Image has been successfully saved in \\\"\" + target_dir + \"\\\" folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = load_filename('Dataset/CUHK/Testing sketch/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\tf-gpu-1\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\tf-gpu-1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Image has been successfully saved in \"Generated Images/Generated_Pixel[1]_Context[0]\" folder\n"
     ]
    }
   ],
   "source": [
    "g_model = load_model('Models/Pixel[1]_Context[0]/g_model.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "\n",
    "pred_images(g_model, \"Generated Images/Generated_Pixel[1]_Context[0]\", filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image has been successfully saved in \"Generated Images/Generated_Pixel[08]_Context[02]\" folder\n"
     ]
    }
   ],
   "source": [
    "g_model = load_model('Models/Pixel[08]_Context[02]/g_model.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "\n",
    "pred_images(g_model, \"Generated Images/Generated_Pixel[08]_Context[02]\", filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image has been successfully saved in \"Generated Images/Generated_Pixel[05]_Context[05]\" folder\n"
     ]
    }
   ],
   "source": [
    "g_model = load_model('Models/Pixel[05]_Context[05]/g_model.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "\n",
    "pred_images(g_model, \"Generated Images/Generated_Pixel[05]_Context[05]\", filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image has been successfully saved in \"Generated Images/Generated_Pixel[02]_Context[08]\" folder\n"
     ]
    }
   ],
   "source": [
    "g_model = load_model('Models/Pixel[02]_Context[08]/g_model.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "\n",
    "pred_images(g_model, \"Generated Images/Generated_Pixel[02]_Context[08]\", filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
